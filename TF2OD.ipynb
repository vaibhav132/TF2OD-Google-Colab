{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhav132/vaibhav132/blob/main/TF2OD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyfFc8VufUyl",
        "outputId": "64be1ab5-030e-46cc-be80-bcef9c928a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-05 17:23:45--  https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py37_4.8 100%[===================>]  81.12M   283MB/s    in 0.3s    \n",
            "\n",
            "2022-07-05 17:23:46 (283 MB/s) - ‘Miniconda3-py37_4.8.2-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# INSTALL CONDA ON GOOGLE COLAB\n",
        "################################################################################\n",
        "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8MeOz0miqJ1",
        "outputId": "ed2c6317-bdff-4225-9415-181c451575ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.8.2\n",
            "  latest version: 4.13.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/tensorflow\n",
            "\n",
            "  added / updated specs:\n",
            "    - pip\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-5.1          |            1_gnu          21 KB\n",
            "    ca-certificates-2022.4.26  |       h06a4308_0         124 KB\n",
            "    certifi-2022.6.15          |   py39h06a4308_0         153 KB\n",
            "    ld_impl_linux-64-2.38      |       h1181459_1         654 KB\n",
            "    libffi-3.3                 |       he6710b0_2          50 KB\n",
            "    libgcc-ng-11.2.0           |       h1234567_1         5.3 MB\n",
            "    libgomp-11.2.0             |       h1234567_1         474 KB\n",
            "    libstdcxx-ng-11.2.0        |       h1234567_1         4.7 MB\n",
            "    ncurses-6.3                |       h5eee18b_3         781 KB\n",
            "    openssl-1.1.1p             |       h5eee18b_0         2.5 MB\n",
            "    pip-21.2.4                 |   py39h06a4308_0         1.8 MB\n",
            "    python-3.9.12              |       h12debd9_1        19.2 MB\n",
            "    readline-8.1.2             |       h7f8727e_1         354 KB\n",
            "    setuptools-61.2.0          |   py39h06a4308_0        1011 KB\n",
            "    sqlite-3.38.5              |       hc218d9a_0         1.0 MB\n",
            "    tk-8.6.12                  |       h1ccaba5_0         3.0 MB\n",
            "    tzdata-2022a               |       hda174b7_0         109 KB\n",
            "    wheel-0.37.1               |     pyhd3eb1b0_0          33 KB\n",
            "    xz-5.2.5                   |       h7f8727e_1         339 KB\n",
            "    zlib-1.2.12                |       h7f8727e_2         106 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        41.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2022.4.26-h06a4308_0\n",
            "  certifi            pkgs/main/linux-64::certifi-2022.6.15-py39h06a4308_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1\n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.3-h5eee18b_3\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1p-h5eee18b_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.4-py39h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.9.12-h12debd9_1\n",
            "  readline           pkgs/main/linux-64::readline-8.1.2-h7f8727e_1\n",
            "  setuptools         pkgs/main/linux-64::setuptools-61.2.0-py39h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.38.5-hc218d9a_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0\n",
            "  tzdata             pkgs/main/noarch::tzdata-2022a-hda174b7_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7f8727e_1\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.12-h7f8727e_2\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "readline-8.1.2       | 354 KB    | : 100% 1.0/1 [00:00<00:00, 14.28it/s]\n",
            "libgcc-ng-11.2.0     | 5.3 MB    | : 100% 1.0/1 [00:00<00:00,  5.76it/s]\n",
            "libstdcxx-ng-11.2.0  | 4.7 MB    | : 100% 1.0/1 [00:00<00:00,  5.04it/s]\n",
            "ld_impl_linux-64-2.3 | 654 KB    | : 100% 1.0/1 [00:00<00:00, 17.38it/s]\n",
            "wheel-0.37.1         | 33 KB     | : 100% 1.0/1 [00:00<00:00, 28.76it/s]\n",
            "setuptools-61.2.0    | 1011 KB   | : 100% 1.0/1 [00:00<00:00, 11.04it/s]\n",
            "sqlite-3.38.5        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00, 17.83it/s]\n",
            "libgomp-11.2.0       | 474 KB    | : 100% 1.0/1 [00:00<00:00, 18.76it/s]\n",
            "ncurses-6.3          | 781 KB    | : 100% 1.0/1 [00:00<00:00,  5.57it/s]\n",
            "openssl-1.1.1p       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  9.62it/s]\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00, 29.64it/s]\n",
            "python-3.9.12        | 19.2 MB   | : 100% 1.0/1 [00:00<00:00,  1.60it/s]               \n",
            "zlib-1.2.12          | 106 KB    | : 100% 1.0/1 [00:00<00:00, 22.55it/s]\n",
            "ca-certificates-2022 | 124 KB    | : 100% 1.0/1 [00:00<00:00, 23.26it/s]\n",
            "certifi-2022.6.15    | 153 KB    | : 100% 1.0/1 [00:00<00:00, 20.71it/s]\n",
            "_openmp_mutex-5.1    | 21 KB     | : 100% 1.0/1 [00:00<00:00, 21.60it/s]\n",
            "xz-5.2.5             | 339 KB    | : 100% 1.0/1 [00:00<00:00, 19.30it/s]\n",
            "pip-21.2.4           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  7.48it/s]\n",
            "tk-8.6.12            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  7.36it/s]\n",
            "tzdata-2022a         | 109 KB    | : 100% 1.0/1 [00:00<00:00, 15.47it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate tensorflow\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda create -n tensorflow pip python=3.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpN0qJVb_eIz",
        "outputId": "617dae66-58d0-474f-f5cf-33d63e6ad97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl (665.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 665.5 MB 23 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Using cached tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (3.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.47.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (3.20.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (2.9.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (4.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/site-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.28.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.25.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "\u001b[31mERROR: tf-models-official 2.9.2 has requirement tensorflow~=2.9.0, but you'll have tensorflow 2.7.0+zzzcolab20220506150900 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-text 2.9.0 has requirement tensorflow<2.10,>=2.9.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you'll have tensorflow 2.7.0+zzzcolab20220506150900 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.1\n",
            "    Uninstalling tensorflow-2.9.1:\n",
            "      Successfully uninstalled tensorflow-2.9.1\n",
            "Successfully installed tensorflow-2.7.0+zzzcolab20220506150900 tensorflow-estimator-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bNwjH59hlHF",
        "outputId": "09ecbdad-d264-460a-81b2-a478855f143c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5ueVmbv8bMs",
        "outputId": "21f16902-af0a-4678-f1cc-a773823cc478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda activate tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZx-7CPc8bOu",
        "outputId": "b9bd5fd7-6586-44a9-f2f3-897e8b215309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "modified      /root/.bashrc\n",
            "\n",
            "==> For changes to take effect, close and re-open your current shell. <==\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!conda init bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRGTRgI98bRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc43b9f-f5de-4698-d355-085abde6081f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.7/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "No action taken.\n"
          ]
        }
      ],
      "source": [
        "!conda init powershell"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cloning TFOD 2.0 Github**"
      ],
      "metadata": {
        "id": "65ADVORRh3Fr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7rM8xyY8bTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4bc8d0-88cc-40c8-d51d-ce3941a5742b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 74952, done.\u001b[K\n",
            "remote: Counting objects: 100% (440/440), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 74952 (delta 261), reused 386 (delta 230), pack-reused 74512\u001b[K\n",
            "Receiving objects: 100% (74952/74952), 580.52 MiB | 17.16 MiB/s, done.\n",
            "Resolving deltas: 100% (53161/53161), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJXeoMFEh6e7",
        "outputId": "b76ddd69-28ad-477a-b45e-9effdaa9b04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "80le_sRBh6hC",
        "outputId": "01347918-50ca-452a-b5e0-2d807bcfead8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "1QC8Gs28h6lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ubrvH6lh6nu",
        "outputId": "7e5bd00b-92fa-4dd6-caa7-17a22aced438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 16.25 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd cocoapi/PythonAPI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUgjrmdgh6pn",
        "outputId": "3604985f-fe7c-4b27-a16f-c2f4430f0811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqAO6cUgh6rn",
        "outputId": "094b6a64-e3d3-4f12-ddeb-77757a0008b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.7/site-packages/numpy/core/include -I../common -I/usr/local/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.7/site-packages/numpy/core/include -I../common -I/usr/local/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Kpycocotools/_mask.c: No such file or directory\n",
            "error: command 'gcc' failed with exit status 1\n",
            "Makefile:3: recipe for target 'all' failed\n",
            "make: *** [all] Error 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r pycocotools /content/models/research"
      ],
      "metadata": {
        "id": "WV7NuH-9h6tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing the Object Detection API**"
      ],
      "metadata": {
        "id": "KQpjctYWiiNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mdeSOUxoil-z",
        "outputId": "34f2a227-de0c-4e1a-fdf7-ba5e013d4c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/cocoapi/PythonAPI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grw5wnwaimAx",
        "outputId": "0f495bfb-1715-4f5a-dd4d-2ad531ed3bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rInoMtIimCz",
        "outputId": "3c744871-8824-40f9-836c-00f3f14b9578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ],
      "metadata": {
        "id": "T9wh4aleimEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NvPhqAlimG0",
        "outputId": "d667885b-fb8c-42a4-a68e-6723c9fc90ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.40.0-cp37-cp37m-manylinux2010_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 45.7 MB/s \n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 60.2 MB/s \n",
            "\u001b[?25hCollecting lxml\n",
            "  Downloading lxml-4.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 50.9 MB/s \n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 49.7 MB/s \n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.30-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 55.6 MB/s \n",
            "\u001b[?25hCollecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from object-detection==0.1) (1.14.0)\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 62.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 64.8 MB/s \n",
            "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.9.2-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (from object-detection==0.1) (2.7.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.14.3 in /usr/local/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.21.6)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux2014_x86_64.whl (527 kB)\n",
            "\u001b[K     |████████████████████████████████| 527 kB 62.5 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting protobuf<4,>=3.12.2\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting httplib2<0.21.0,>=0.8\n",
            "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (4.3.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.5.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.33.1 in /usr/local/lib/python3.7/site-packages (from apache-beam->object-detection==0.1) (1.47.0)\n",
            "Collecting pyarrow<8.0.0,>=0.15.1\n",
            "  Downloading pyarrow-7.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.7 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.6-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting pytz>=2018.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting python-dateutil<3,>=2.8.0\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting orjson<4.0\n",
            "  Downloading orjson-3.7.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.8 MB/s \n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[K     |████████████████████████████████| 930 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/site-packages (from tf-slim->object-detection==0.1) (1.1.0)\n",
            "Collecting opencv-python>=4.1.0.25\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.9 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 16.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.5 MB/s \n",
            "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.52.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 49.6 MB/s \n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text~=2.9.0\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 51.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.4.3\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 13.4 MB/s \n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.2 MB/s \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 104 kB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow~=2.9.0\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.9 kB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.26.0 in /usr/local/lib/python3.7/site-packages (from tensorflow_io->object-detection==0.1) (0.26.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.8)\n",
            "Collecting charset-normalizer<3,>=2\n",
            "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.25.8)\n",
            "Collecting importlib-resources; python_version < \"3.9\"\n",
            "  Downloading importlib_resources-5.8.0-py3-none-any.whl (28 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.9.0-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting etils[epath]\n",
            "  Downloading etils-0.6.0-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (4.42.1)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Collecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "Collecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.9.0)\n",
            "Collecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting python-slugify\n",
            "  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/site-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 16.5 MB/s \n",
            "\u001b[?25hCollecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting dm-tree~=0.1.1\n",
            "  Downloading dm_tree-0.1.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 68.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.1)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (45.2.0.post20200210)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.56.3-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.2.0)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (4.12.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, pycocotools, crcmod, dill, kaggle, seqeval, py-cpuinfo, docopt, promise\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1694830 sha256=cd6da8c27ba23afb1d27c677560377f7d601cb9c6d96fd13dc74481508eade2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n7xp_z97/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=4dc3197aa4d8ded626b216098b4932da324b798d8607532e03094ee43eddff2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=273732 sha256=8bf157f214faf0a91ddbf29d11e78335b1908c1419859e8c196c425900de34d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp37-cp37m-linux_x86_64.whl size=36458 sha256=9919f51b0fd122dd9cf77aa63f97d1a4eca15fbe521ff0a10ebb13fc29a5a689\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/9a/e9/49e627353476cec8484343c4ab656f1e0d783ee77b9dde2d1f\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=62b968c7b2d4e06d72e457123e5ce9939b9e63ee0f11f696e8ae07f4468ffe9d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=b0890e24281ea7c70f5639e930bed7ca24cb88b837477539008047807903dcfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=80a277700b778c26fab7cefb42785cd27b1689bf68f9653ce2fc5200af937b3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22245 sha256=3b759e8cb2e5a9669975ff4fc89855d89f3a772180dedbb7b4233cb91dca7b5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=4793f2abbb6a5f04ef82b8e1935de768b6a2c4f9e9b75203721531fc97257e85\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21495 sha256=891f86374578a1f5a792a89d57881c8826e542161b35309a419ab59d47328e64\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
            "Successfully built object-detection avro-python3 pycocotools crcmod dill kaggle seqeval py-cpuinfo docopt promise\n",
            "\u001b[31mERROR: tensorflow 2.9.1 has requirement keras<2.10.0,>=2.9.0rc0, but you'll have keras 2.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.9.1 has requirement protobuf<3.20,>=3.9.2, but you'll have protobuf 3.20.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.9.1 has requirement protobuf<3.20,>=3.9.2, but you'll have protobuf 3.20.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: avro-python3, pymongo, docopt, charset-normalizer, requests, hdfs, protobuf, pyparsing, pydot, httplib2, fastavro, pyarrow, crcmod, proto-plus, pytz, dill, cloudpickle, python-dateutil, orjson, apache-beam, pillow, lxml, packaging, kiwisolver, fonttools, cycler, matplotlib, Cython, contextlib2, tf-slim, pycocotools, opencv-python, lvis, scipy, pandas, importlib-resources, googleapis-common-protos, tensorflow-metadata, etils, toml, promise, tensorflow-datasets, typeguard, tensorflow-addons, google-api-core, uritemplate, google-auth-httplib2, google-api-python-client, text-unidecode, python-slugify, kaggle, tensorflow-estimator, flatbuffers, tensorflow, tensorflow-hub, tensorflow-text, oauth2client, psutil, joblib, threadpoolctl, scikit-learn, seqeval, regex, tabulate, colorama, portalocker, sacrebleu, gin-config, pyyaml, py-cpuinfo, opencv-python-headless, dm-tree, tensorflow-model-optimization, sentencepiece, tf-models-official, tensorflow-io, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.22.0\n",
            "    Uninstalling requests-2.22.0:\n",
            "      Successfully uninstalled requests-2.22.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.21.2\n",
            "    Uninstalling protobuf-4.21.2:\n",
            "      Successfully uninstalled protobuf-4.21.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0+zzzcolab20220506150900\n",
            "    Uninstalling tensorflow-2.7.0+zzzcolab20220506150900:\n",
            "      Successfully uninstalled tensorflow-2.7.0+zzzcolab20220506150900\n",
            "Successfully installed Cython-0.29.30 apache-beam-2.40.0 avro-python3-1.10.2 charset-normalizer-2.1.0 cloudpickle-2.1.0 colorama-0.4.5 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.1.1 dm-tree-0.1.7 docopt-0.6.2 etils-0.6.0 fastavro-1.5.2 flatbuffers-1.12 fonttools-4.33.3 gin-config-0.5.0 google-api-core-2.8.2 google-api-python-client-2.52.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.56.3 hdfs-2.7.0 httplib2-0.20.4 importlib-resources-5.8.0 joblib-1.1.0 kaggle-1.5.12 kiwisolver-1.4.3 lvis-0.5.3 lxml-4.9.1 matplotlib-3.5.2 oauth2client-4.1.3 object-detection-0.1 opencv-python-4.6.0.66 opencv-python-headless-4.6.0.66 orjson-3.7.6 packaging-21.3 pandas-1.3.5 pillow-9.2.0 portalocker-2.4.0 promise-2.3 proto-plus-1.20.6 protobuf-3.20.1 psutil-5.9.1 py-cpuinfo-8.0.0 pyarrow-7.0.0 pycocotools-2.0.4 pydot-1.4.2 pymongo-3.12.3 pyparsing-2.4.7 python-dateutil-2.8.2 python-slugify-6.1.2 pytz-2022.1 pyyaml-5.4.1 regex-2022.6.2 requests-2.28.1 sacrebleu-2.1.0 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.96 seqeval-1.2.2 tabulate-0.8.10 tensorflow-2.9.1 tensorflow-addons-0.17.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-0.26.0 tensorflow-metadata-1.9.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 text-unidecode-1.3 tf-models-official-2.9.2 tf-slim-1.1.0 threadpoolctl-3.1.0 toml-0.10.2 typeguard-2.13.3 uritemplate-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_liCPcyimJd",
        "outputId": "160c41f0-5b21-4b6b-caa0-90336609a265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.6: /usr/local/bin/python\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-07-05 17:31:48.623089: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0705 17:31:48.858771 140084745766784 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.42s\n",
            "I0705 17:31:49.217464 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.42s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "I0705 17:31:49.714842 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.5s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "I0705 17:31:49.974261 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
            "I0705 17:31:50.207056 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.23s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.56s\n",
            "I0705 17:31:52.763279 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0705 17:31:52.764209 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0705 17:31:52.787448 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0705 17:31:52.807946 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0705 17:31:52.822726 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "I0705 17:31:52.926213 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I0705 17:31:53.016967 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0705 17:31:53.109361 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0705 17:31:53.201375 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0705 17:31:53.292940 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0705 17:31:53.320062 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0705 17:31:53.504648 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0705 17:31:53.504787 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0705 17:31:53.504857 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0705 17:31:53.507025 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:53.523358 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:53.523468 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:53.582128 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:53.582281 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:53.731133 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:53.731282 140084745766784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0705 17:31:53.884155 140084745766784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0705 17:31:53.884361 140084745766784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0705 17:31:54.111560 140084745766784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0705 17:31:54.111734 140084745766784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0705 17:31:54.336756 140084745766784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0705 17:31:54.336906 140084745766784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0705 17:31:54.639378 140084745766784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0705 17:31:54.639533 140084745766784 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0705 17:31:54.709600 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0705 17:31:54.739940 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:31:54.787796 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0705 17:31:54.787918 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0705 17:31:54.787986 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0705 17:31:54.789628 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:54.805207 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:54.805320 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:54.931499 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:54.931638 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:55.149572 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:55.149721 140084745766784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0705 17:31:55.371431 140084745766784 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0705 17:31:55.371585 140084745766784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0705 17:31:55.665426 140084745766784 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0705 17:31:55.665578 140084745766784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0705 17:31:56.110157 140084745766784 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0705 17:31:56.110332 140084745766784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0705 17:31:56.484932 140084745766784 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0705 17:31:56.485094 140084745766784 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0705 17:31:56.630410 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0705 17:31:56.657361 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:31:56.715590 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0705 17:31:56.715713 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0705 17:31:56.715781 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0705 17:31:56.717271 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:56.731500 140084745766784 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0705 17:31:56.731601 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:56.848014 140084745766784 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0705 17:31:56.848154 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:57.079363 140084745766784 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0705 17:31:57.079513 140084745766784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0705 17:31:57.309027 140084745766784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0705 17:31:57.309261 140084745766784 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0705 17:31:57.617564 140084745766784 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0705 17:31:57.617727 140084745766784 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0705 17:31:57.921851 140084745766784 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0705 17:31:57.922008 140084745766784 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0705 17:31:58.294648 140084745766784 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0705 17:31:58.294814 140084745766784 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0705 17:31:58.440652 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0705 17:31:58.468309 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:31:58.527639 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0705 17:31:58.527760 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0705 17:31:58.527828 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0705 17:31:58.529330 140084745766784 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0705 17:31:58.543775 140084745766784 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0705 17:31:58.543879 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:31:58.661767 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:31:58.661889 140084745766784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0705 17:31:58.882946 140084745766784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0705 17:31:58.883109 140084745766784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0705 17:31:59.120226 140084745766784 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0705 17:31:59.120405 140084745766784 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0705 17:31:59.495327 140084745766784 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0705 17:31:59.495486 140084745766784 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0705 17:31:59.866866 140084745766784 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0705 17:31:59.867038 140084745766784 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0705 17:32:00.325077 140084745766784 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0705 17:32:00.325255 140084745766784 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0705 17:32:00.475941 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0705 17:32:00.503711 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:32:00.565180 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0705 17:32:00.565337 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0705 17:32:00.565407 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0705 17:32:00.566933 140084745766784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0705 17:32:00.581894 140084745766784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0705 17:32:00.581993 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:32:00.887088 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:32:00.887271 140084745766784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0705 17:32:01.198389 140084745766784 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0705 17:32:01.198546 140084745766784 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0705 17:32:01.500650 140084745766784 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0705 17:32:01.500814 140084745766784 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0705 17:32:01.939721 140084745766784 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0705 17:32:01.939886 140084745766784 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0705 17:32:02.400063 140084745766784 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0705 17:32:02.400236 140084745766784 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0705 17:32:03.004331 140084745766784 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0705 17:32:03.004513 140084745766784 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0705 17:32:03.153772 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0705 17:32:03.182909 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:32:03.255714 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0705 17:32:03.255852 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0705 17:32:03.255924 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0705 17:32:03.257443 140084745766784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0705 17:32:03.272063 140084745766784 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0705 17:32:03.272166 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:32:03.450917 140084745766784 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0705 17:32:03.451058 140084745766784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0705 17:32:03.819332 140084745766784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0705 17:32:03.819485 140084745766784 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0705 17:32:04.197659 140084745766784 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0705 17:32:04.197836 140084745766784 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0705 17:32:04.714768 140084745766784 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0705 17:32:04.714932 140084745766784 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0705 17:32:05.239992 140084745766784 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0705 17:32:05.240157 140084745766784 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0705 17:32:05.914057 140084745766784 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0705 17:32:05.914240 140084745766784 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0705 17:32:06.150834 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0705 17:32:06.178254 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:32:06.436369 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0705 17:32:06.436530 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0705 17:32:06.436599 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0705 17:32:06.438234 140084745766784 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0705 17:32:06.457903 140084745766784 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0705 17:32:06.458013 140084745766784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0705 17:32:06.635768 140084745766784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0705 17:32:06.635901 140084745766784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0705 17:32:07.090301 140084745766784 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0705 17:32:07.090461 140084745766784 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0705 17:32:07.536808 140084745766784 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0705 17:32:07.536975 140084745766784 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0705 17:32:08.136769 140084745766784 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0705 17:32:08.136936 140084745766784 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0705 17:32:08.740160 140084745766784 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0705 17:32:08.740344 140084745766784 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0705 17:32:09.581995 140084745766784 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0705 17:32:09.582161 140084745766784 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0705 17:32:09.798086 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0705 17:32:09.829511 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0705 17:32:09.926447 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0705 17:32:09.926585 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0705 17:32:09.926654 140084745766784 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0705 17:32:09.928413 140084745766784 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0705 17:32:09.943669 140084745766784 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0705 17:32:09.943780 140084745766784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0705 17:32:10.195200 140084745766784 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0705 17:32:10.195368 140084745766784 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0705 17:32:10.722294 140084745766784 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0705 17:32:10.722446 140084745766784 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0705 17:32:11.249321 140084745766784 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0705 17:32:11.249494 140084745766784 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0705 17:32:11.994399 140084745766784 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0705 17:32:11.994568 140084745766784 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0705 17:32:12.974469 140084745766784 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0705 17:32:12.974636 140084745766784 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0705 17:32:13.950389 140084745766784 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0705 17:32:13.950556 140084745766784 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0705 17:32:14.256128 140084745766784 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0705 17:32:14.292539 140084745766784 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.08s\n",
            "I0705 17:32:14.401483 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 21.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0705 17:32:14.407184 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0705 17:32:14.408794 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0705 17:32:14.409287 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0705 17:32:14.410700 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0705 17:32:14.411981 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0705 17:32:14.412423 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0705 17:32:14.413382 140084745766784 test_util.py:2459] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 26.612s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training custom object detector**"
      ],
      "metadata": {
        "id": "A7VTJ5wWlI9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/training_demo/pre-trained-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHwNXu1fimMv",
        "outputId": "5fbb7298-cc82-4fb8-e632-e1afb22825e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_demo/pre-trained-models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OvauLbsimQK",
        "outputId": "d5f85f56-8968-4c76-a4f1-0cb1d1915d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-05 17:32:15--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.24.128, 2404:6800:4003:c03::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.24.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M   294MB/s    in 1.3s    \n",
            "\n",
            "2022-07-05 17:32:17 (294 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zys5HA_Wmdi_",
        "outputId": "c0350b18-50c2-4c74-f660-d7d81a7c48e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GJj7DtRSmdle",
        "outputId": "468daca8-dbe7-4cc3-8f42-e5141f571ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_demo/pre-trained-models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/training_demo"
      ],
      "metadata": {
        "id": "J_oLYyzymdor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6ef816-4e7c-4f30-8f79-5b71f580ccff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_demo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ismV0pq5rh-X",
        "outputId": "1819b3de-3ecd-4448-8834-dd7900bb0eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GbGlH_ilu74v",
        "outputId": "a3ecf3aa-457e-4b76-8b9d-6ced1dc6c848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_demo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC2Y4Os9u9L_",
        "outputId": "c6a30aee-d359-4038-b0d9-1034f90ebdd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported-models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.7.0"
      ],
      "metadata": {
        "id": "QCNzcRqgbbLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raMSxl-Z9wGA",
        "outputId": "53360151-d874-4d7e-d69a-de7ffc56aa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-05 17:35:49.224348: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0705 17:35:49.227697 140225671137152 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0705 17:35:49.232070 140225671137152 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0705 17:35:49.232248 140225671137152 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0705 17:35:49.258931 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "I0705 17:35:49.262572 140225671137152 dataset_builder.py:162] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "I0705 17:35:49.262749 140225671137152 dataset_builder.py:79] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0705 17:35:49.262849 140225671137152 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0705 17:35:49.262922 140225671137152 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0705 17:35:49.265630 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0705 17:35:49.285737 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0705 17:35:56.320597 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0705 17:35:59.459439 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0705 17:36:01.141522 140225671137152 deprecation.py:347] From /usr/local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-07-05 17:36:05.069921: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator0/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n",
            "/usr/local/lib/python3.7/site-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.401159 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.402395 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.404425 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.405302 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.407334 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.408181 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.410581 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.411455 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.413088 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0705 17:36:44.413949 140225671137152 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0705 17:36:45.649154 140221070636800 deprecation.py:551] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 2.444s\n",
            "I0705 17:40:49.631948 140225671137152 model_lib_v2.py:707] Step 100 per-step time 2.444s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34154963,\n",
            " 'Loss/localization_loss': 0.20182934,\n",
            " 'Loss/regularization_loss': 71.60903,\n",
            " 'Loss/total_loss': 72.15241,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0705 17:40:49.632396 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.34154963,\n",
            " 'Loss/localization_loss': 0.20182934,\n",
            " 'Loss/regularization_loss': 71.60903,\n",
            " 'Loss/total_loss': 72.15241,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.849s\n",
            "I0705 17:43:54.505877 140225671137152 model_lib_v2.py:707] Step 200 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2725217,\n",
            " 'Loss/localization_loss': 0.17643669,\n",
            " 'Loss/regularization_loss': 70.7583,\n",
            " 'Loss/total_loss': 71.20726,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0705 17:43:54.506232 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.2725217,\n",
            " 'Loss/localization_loss': 0.17643669,\n",
            " 'Loss/regularization_loss': 70.7583,\n",
            " 'Loss/total_loss': 71.20726,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.850s\n",
            "I0705 17:46:59.536746 140225671137152 model_lib_v2.py:707] Step 300 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22920632,\n",
            " 'Loss/localization_loss': 0.112647705,\n",
            " 'Loss/regularization_loss': 69.82909,\n",
            " 'Loss/total_loss': 70.17094,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0705 17:46:59.537134 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.22920632,\n",
            " 'Loss/localization_loss': 0.112647705,\n",
            " 'Loss/regularization_loss': 69.82909,\n",
            " 'Loss/total_loss': 70.17094,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.850s\n",
            "I0705 17:50:04.527190 140225671137152 model_lib_v2.py:707] Step 400 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18802214,\n",
            " 'Loss/localization_loss': 0.04459401,\n",
            " 'Loss/regularization_loss': 68.838486,\n",
            " 'Loss/total_loss': 69.0711,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0705 17:50:04.527540 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.18802214,\n",
            " 'Loss/localization_loss': 0.04459401,\n",
            " 'Loss/regularization_loss': 68.838486,\n",
            " 'Loss/total_loss': 69.0711,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.849s\n",
            "I0705 17:53:09.417943 140225671137152 model_lib_v2.py:707] Step 500 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19864503,\n",
            " 'Loss/localization_loss': 0.053415217,\n",
            " 'Loss/regularization_loss': 67.789505,\n",
            " 'Loss/total_loss': 68.041565,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0705 17:53:09.418297 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.19864503,\n",
            " 'Loss/localization_loss': 0.053415217,\n",
            " 'Loss/regularization_loss': 67.789505,\n",
            " 'Loss/total_loss': 68.041565,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.850s\n",
            "I0705 17:56:14.406818 140225671137152 model_lib_v2.py:707] Step 600 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15274446,\n",
            " 'Loss/localization_loss': 0.04726921,\n",
            " 'Loss/regularization_loss': 66.68523,\n",
            " 'Loss/total_loss': 66.88524,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0705 17:56:14.407151 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.15274446,\n",
            " 'Loss/localization_loss': 0.04726921,\n",
            " 'Loss/regularization_loss': 66.68523,\n",
            " 'Loss/total_loss': 66.88524,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.850s\n",
            "I0705 17:59:19.362429 140225671137152 model_lib_v2.py:707] Step 700 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15798828,\n",
            " 'Loss/localization_loss': 0.035576805,\n",
            " 'Loss/regularization_loss': 65.528946,\n",
            " 'Loss/total_loss': 65.72251,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0705 17:59:19.362777 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.15798828,\n",
            " 'Loss/localization_loss': 0.035576805,\n",
            " 'Loss/regularization_loss': 65.528946,\n",
            " 'Loss/total_loss': 65.72251,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.848s\n",
            "I0705 18:02:24.207900 140225671137152 model_lib_v2.py:707] Step 800 per-step time 1.848s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1494706,\n",
            " 'Loss/localization_loss': 0.039002582,\n",
            " 'Loss/regularization_loss': 64.323906,\n",
            " 'Loss/total_loss': 64.51238,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0705 18:02:24.208258 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1494706,\n",
            " 'Loss/localization_loss': 0.039002582,\n",
            " 'Loss/regularization_loss': 64.323906,\n",
            " 'Loss/total_loss': 64.51238,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.851s\n",
            "I0705 18:05:29.294539 140225671137152 model_lib_v2.py:707] Step 900 per-step time 1.851s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15612008,\n",
            " 'Loss/localization_loss': 0.040835094,\n",
            " 'Loss/regularization_loss': 63.073624,\n",
            " 'Loss/total_loss': 63.27058,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0705 18:05:29.294867 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.15612008,\n",
            " 'Loss/localization_loss': 0.040835094,\n",
            " 'Loss/regularization_loss': 63.073624,\n",
            " 'Loss/total_loss': 63.27058,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.850s\n",
            "I0705 18:08:34.298241 140225671137152 model_lib_v2.py:707] Step 1000 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13650727,\n",
            " 'Loss/localization_loss': 0.04084736,\n",
            " 'Loss/regularization_loss': 61.78165,\n",
            " 'Loss/total_loss': 61.959003,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0705 18:08:34.298571 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.13650727,\n",
            " 'Loss/localization_loss': 0.04084736,\n",
            " 'Loss/regularization_loss': 61.78165,\n",
            " 'Loss/total_loss': 61.959003,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.873s\n",
            "I0705 18:11:41.600764 140225671137152 model_lib_v2.py:707] Step 1100 per-step time 1.873s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.118000545,\n",
            " 'Loss/localization_loss': 0.027908545,\n",
            " 'Loss/regularization_loss': 60.451546,\n",
            " 'Loss/total_loss': 60.597454,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0705 18:11:41.601107 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.118000545,\n",
            " 'Loss/localization_loss': 0.027908545,\n",
            " 'Loss/regularization_loss': 60.451546,\n",
            " 'Loss/total_loss': 60.597454,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.851s\n",
            "I0705 18:14:46.671667 140225671137152 model_lib_v2.py:707] Step 1200 per-step time 1.851s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11188669,\n",
            " 'Loss/localization_loss': 0.02195847,\n",
            " 'Loss/regularization_loss': 59.086876,\n",
            " 'Loss/total_loss': 59.220722,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0705 18:14:46.672008 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.11188669,\n",
            " 'Loss/localization_loss': 0.02195847,\n",
            " 'Loss/regularization_loss': 59.086876,\n",
            " 'Loss/total_loss': 59.220722,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.850s\n",
            "I0705 18:17:51.669398 140225671137152 model_lib_v2.py:707] Step 1300 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14200787,\n",
            " 'Loss/localization_loss': 0.036192555,\n",
            " 'Loss/regularization_loss': 57.691334,\n",
            " 'Loss/total_loss': 57.869534,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0705 18:17:51.669763 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.14200787,\n",
            " 'Loss/localization_loss': 0.036192555,\n",
            " 'Loss/regularization_loss': 57.691334,\n",
            " 'Loss/total_loss': 57.869534,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.850s\n",
            "I0705 18:20:56.660038 140225671137152 model_lib_v2.py:707] Step 1400 per-step time 1.850s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11137272,\n",
            " 'Loss/localization_loss': 0.020403108,\n",
            " 'Loss/regularization_loss': 56.268642,\n",
            " 'Loss/total_loss': 56.400417,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0705 18:20:56.660394 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.11137272,\n",
            " 'Loss/localization_loss': 0.020403108,\n",
            " 'Loss/regularization_loss': 56.268642,\n",
            " 'Loss/total_loss': 56.400417,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.847s\n",
            "I0705 18:24:01.354235 140225671137152 model_lib_v2.py:707] Step 1500 per-step time 1.847s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1039962,\n",
            " 'Loss/localization_loss': 0.016305193,\n",
            " 'Loss/regularization_loss': 54.82251,\n",
            " 'Loss/total_loss': 54.94281,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0705 18:24:01.354575 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1039962,\n",
            " 'Loss/localization_loss': 0.016305193,\n",
            " 'Loss/regularization_loss': 54.82251,\n",
            " 'Loss/total_loss': 54.94281,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.849s\n",
            "I0705 18:27:06.211489 140225671137152 model_lib_v2.py:707] Step 1600 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.110113636,\n",
            " 'Loss/localization_loss': 0.01964399,\n",
            " 'Loss/regularization_loss': 53.3565,\n",
            " 'Loss/total_loss': 53.486256,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0705 18:27:06.211828 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.110113636,\n",
            " 'Loss/localization_loss': 0.01964399,\n",
            " 'Loss/regularization_loss': 53.3565,\n",
            " 'Loss/total_loss': 53.486256,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.849s\n",
            "I0705 18:30:11.111601 140225671137152 model_lib_v2.py:707] Step 1700 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12945,\n",
            " 'Loss/localization_loss': 0.023633434,\n",
            " 'Loss/regularization_loss': 51.87418,\n",
            " 'Loss/total_loss': 52.027264,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0705 18:30:11.111933 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.12945,\n",
            " 'Loss/localization_loss': 0.023633434,\n",
            " 'Loss/regularization_loss': 51.87418,\n",
            " 'Loss/total_loss': 52.027264,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.849s\n",
            "I0705 18:33:16.001172 140225671137152 model_lib_v2.py:707] Step 1800 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08879469,\n",
            " 'Loss/localization_loss': 0.019607687,\n",
            " 'Loss/regularization_loss': 50.379158,\n",
            " 'Loss/total_loss': 50.48756,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0705 18:33:16.001511 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.08879469,\n",
            " 'Loss/localization_loss': 0.019607687,\n",
            " 'Loss/regularization_loss': 50.379158,\n",
            " 'Loss/total_loss': 50.48756,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.848s\n",
            "I0705 18:36:20.771853 140225671137152 model_lib_v2.py:707] Step 1900 per-step time 1.848s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.074514635,\n",
            " 'Loss/localization_loss': 0.011472513,\n",
            " 'Loss/regularization_loss': 48.87489,\n",
            " 'Loss/total_loss': 48.960876,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0705 18:36:20.772196 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.074514635,\n",
            " 'Loss/localization_loss': 0.011472513,\n",
            " 'Loss/regularization_loss': 48.87489,\n",
            " 'Loss/total_loss': 48.960876,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.849s\n",
            "I0705 18:39:25.660308 140225671137152 model_lib_v2.py:707] Step 2000 per-step time 1.849s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.105881654,\n",
            " 'Loss/localization_loss': 0.016045768,\n",
            " 'Loss/regularization_loss': 47.36496,\n",
            " 'Loss/total_loss': 47.48689,\n",
            " 'learning_rate': nan}\n",
            "I0705 18:39:25.660646 140225671137152 model_lib_v2.py:708] {'Loss/classification_loss': 0.105881654,\n",
            " 'Loss/localization_loss': 0.016045768,\n",
            " 'Loss/regularization_loss': 47.36496,\n",
            " 'Loss/total_loss': 47.48689,\n",
            " 'learning_rate': nan}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_demo/exported-models/my_model"
      ],
      "metadata": {
        "id": "yGjfFZrY9wKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f55343-a3cb-4fe5-ebc1-480a2e37906c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-05 19:06:22.196950: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0705 19:06:22.355980 139634974459776 deprecation.py:619] From /usr/local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7efe602ab250>, because it is not built.\n",
            "W0705 19:06:42.055618 139634974459776 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7efe602ab250>, because it is not built.\n",
            "2022-07-05 19:07:00.518146: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0705 19:07:27.968619 139634974459776 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/training_demo/exported-models/my_model/saved_model/assets\n",
            "I0705 19:07:38.561805 139634974459776 builder_impl.py:784] Assets written to: /content/training_demo/exported-models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported-models/my_model/pipeline.config\n",
            "I0705 19:07:39.679419 139634974459776 config_util.py:254] Writing pipeline config file to /content/training_demo/exported-models/my_model/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inferencing my trained models**"
      ],
      "metadata": {
        "id": "lK1PQ4q2wph8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "axeCq7zb9wzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TF2OD.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}